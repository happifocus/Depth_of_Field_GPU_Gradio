{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377991f8-6a9e-4b62-a818-d93bfe5273bf",
   "metadata": {},
   "source": [
    "# AI-Driven Depth of Field Simulations with Gradio and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52da8ff-9e68-4642-83ea-0b523baa4413",
   "metadata": {},
   "source": [
    "This notebook showcases the setup of a GPU-accelerated Depth of Field simulation on uploaded images:\n",
    "- Generate depth maps from images using a pre-trained model.\n",
    "- Apply a depth of field effect to images based on the generated depth map.\n",
    "\n",
    "To enhance the user experience, a Gradio interface is implemented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a607c-e150-4af6-aad5-f327c3236bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a6d47-d549-4966-a5d8-849a7182eccc",
   "metadata": {},
   "source": [
    "## 1. Project Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676781a0-e7a6-44fb-a2a7-344b66bfc4b2",
   "metadata": {},
   "source": [
    "To keep your files organized, create a separate folder for the project. \n",
    "Place the notebook file into the project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e1b97-06c5-4390-bb88-e87bcf5aa8e2",
   "metadata": {},
   "source": [
    "## 2. Anaconda Navigator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130916f-cd1b-4d9a-adee-e0ef79a0bf4f",
   "metadata": {},
   "source": [
    "**Environments**: Create a new environment, providing a name and selecting the Python package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21959190-bc6c-4f2a-a880-197086ce42c2",
   "metadata": {},
   "source": [
    "**Home**: Install JupyterLab and launch it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa413e9-77ad-4834-a33d-4f665edb43b0",
   "metadata": {},
   "source": [
    "## 3. JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9bf426-7831-4a85-9c9f-1f65a66ff757",
   "metadata": {},
   "source": [
    "Navigate to the project folder. Open the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd90879-7601-46b9-b71d-c137161941c7",
   "metadata": {},
   "source": [
    "Verify that you are working in the newly created environment by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918dd19-5c6c-43f1-8918-77b419c200d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a18b8-7f5d-4498-af7e-0b4823233839",
   "metadata": {},
   "source": [
    "## 4. Connecting CUDA for GPU Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fd92d-49e9-437f-be4f-9447f2460be5",
   "metadata": {},
   "source": [
    "In the Anaconda Navigator, go to the **Terminal** of the current environment and run: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "43f0f57b-f0e5-494d-8307-641b2073c13c",
   "metadata": {},
   "source": [
    "conda install pytorch torchvision pytorch-cuda -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84547e59-fbbe-436f-a6f2-1374d7771f43",
   "metadata": {},
   "source": [
    "## 5. Verifying CUDA-enabled GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b560f7a-6037-4ecb-a4c5-8ee5d565239d",
   "metadata": {},
   "source": [
    "Check if CUDA is available by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e350ef8-cc15-4288-bbc0-344d32b40ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26809e0-dcd3-4927-a149-040efcc8b7ee",
   "metadata": {},
   "source": [
    "## 6. Install Gradio, Transformers, Pillow, OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248ab2e-4583-46b8-b03c-782ffb275fbb",
   "metadata": {},
   "source": [
    "Again, use the **Terminal** of the Anaconda environment for installation:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e48ad49-cd17-4a0f-a0ee-30c58816cc20",
   "metadata": {},
   "source": [
    "conda install conda-forge::gradio\n",
    "conda install transformers\n",
    "pip install Pillow\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf63ea7-4b8e-4482-970f-e85ff8aff416",
   "metadata": {},
   "source": [
    "## 7. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa7028-18f5-4ff7-a8fe-33bb48479384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from transformers import DPTForDepthEstimation, DPTImageProcessor\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349971f1-6a43-4eee-b78a-3a3dbaed85a3",
   "metadata": {},
   "source": [
    "## 8. The Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0307f3-44df-4bb0-99d2-0d656018d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)  # Configure logging to show INFO level messages\n",
    "logger = logging.getLogger(__name__)  # Create a logger for this module\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, otherwise use CPU\n",
    "logger.info(f\"Using device: {device}\")  # Log the device being used\n",
    "\n",
    "# Load model and processor - https://huggingface.co/Intel/dpt-hybrid-midas\n",
    "model_name = \"Intel/dpt-hybrid-midas\"  # Name of the pre-trained depth estimation model\n",
    "model = DPTForDepthEstimation.from_pretrained(model_name).to(device)  # Load the model and move it to the appropriate device\n",
    "processor = DPTImageProcessor.from_pretrained(model_name)  # Load the image processor for the model\n",
    "\n",
    "# Define function to create a depth map\n",
    "def create_depth_map(original_image):\n",
    "    # Prepare image for the model\n",
    "    inputs = processor(images=original_image, return_tensors=\"pt\").to(device)  # Process the image and move it to the device\n",
    "    \n",
    "    # Generate depth map\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = model(**inputs)  # Run the model on the input image\n",
    "        predicted_depth = outputs.predicted_depth  # Extract the predicted depth\n",
    "    \n",
    "    # Normalize depth values\n",
    "    depth_map = torch.nn.functional.interpolate(  # Resize the depth map to match the original image size\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=original_image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze().cpu().numpy()  # Convert to numpy array\n",
    "\n",
    "    # Normalize the depth map values to a range between 0 and 1\n",
    "    depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())  \n",
    "    return depth_map\n",
    "\n",
    "# Define function to apply depth of field effect\n",
    "def apply_depth_of_field(original_image, depth_map, blur_strength=15):\n",
    "    # Convert images to numpy arrays\n",
    "    original_image_np = np.array(original_image)  # Convert PIL image to numpy array\n",
    "    depth_map_np = (depth_map * 255).astype(np.uint8)  # Scale depth map to [0, 255]\n",
    "    depth_map_np = cv2.cvtColor(depth_map_np, cv2.COLOR_GRAY2BGR)  # Convert to 3 channels for mask\n",
    "\n",
    "    # Normalize the depth map to range [0, 1]\n",
    "    depth_map_normalized = depth_map_np[:, :, 0] / 255.0\n",
    "\n",
    "    # Create a mask based on the depth map\n",
    "    threshold = np.mean(depth_map_normalized)  # Average depth as a threshold\n",
    "    mask = depth_map_normalized < threshold  # Areas closer than the threshold will be blurred\n",
    "\n",
    "    # Ensure blur_strength is odd and within a reasonable range\n",
    "    blur_strength = max(3, min(blur_strength, 51))  # Limit between 3 and 51\n",
    "    if blur_strength % 2 == 0:\n",
    "        blur_strength += 1  # Make it odd if it's even\n",
    "\n",
    "    # Create a blurred version of the original image\n",
    "    blurred_image = cv2.GaussianBlur(original_image_np, (blur_strength, blur_strength), 0)\n",
    "\n",
    "    # Combine the original and blurred images based on the mask\n",
    "    output_image = np.where(mask[:, :, np.newaxis], blurred_image, original_image_np)\n",
    "\n",
    "    return Image.fromarray(output_image.astype(np.uint8)), depth_map_np\n",
    "\n",
    "# Define main image processing function\n",
    "def process_image(original_image, blur_strength, state):\n",
    "    try:\n",
    "        if original_image is None and state is None:  # Check if no image is uploaded and no state exists\n",
    "            logger.warning(\"No image uploaded\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        if original_image is not None:  # If a new image is uploaded\n",
    "            state = {\"original_image\": original_image, \"depth_map\": create_depth_map(original_image)}  # Create new state\n",
    "        elif state is not None:  # If state exists (reusing previous image)\n",
    "            original_image = state[\"original_image\"]  # Retrieve original image from state\n",
    "\n",
    "        logger.info(f\"Processing image with blur strength: {blur_strength}\")\n",
    "        \n",
    "        # Apply depth of field effect\n",
    "        output_image, depth_map_image = apply_depth_of_field(original_image, state[\"depth_map\"], blur_strength)\n",
    "\n",
    "        # Save depth map and output image as PNG files\n",
    "        depth_map_pil = Image.fromarray((state[\"depth_map\"] * 255).astype(np.uint8))  # Convert depth map to PIL Image\n",
    "        temp_file_depth = tempfile.NamedTemporaryFile(delete=False, suffix='.png')  # Create temporary file for depth map\n",
    "        depth_map_pil.save(temp_file_depth.name)  # Save depth map\n",
    "\n",
    "        temp_file_output = tempfile.NamedTemporaryFile(delete=False, suffix='.png')  # Create temporary file for output image\n",
    "        output_image.save(temp_file_output.name)  # Save output image\n",
    "\n",
    "        logger.info(\"Processing completed successfully\")\n",
    "        return output_image, temp_file_depth.name, temp_file_output.name, state\n",
    "\n",
    "    # Catch any exception during the process, log error and return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in process_image: {str(e)}\")\n",
    "        return None, None, None, state\n",
    "\n",
    "# Define Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_image,  # Main function to process images\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Upload Original Image (PNG/JPEG)\"),  # Input for original image\n",
    "        gr.Slider(minimum=1, maximum=50, step=1, value=15, label=\"Blur Strength\"),  # Slider for blur strength\n",
    "        \"state\"  # Hidden state input\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Image(label=\"Output Image with Depth of Field\"),  # Output for processed image\n",
    "        gr.File(label=\"Download Depth Map\"),  # Output for depth map file\n",
    "        gr.File(label=\"Download Processed Image\"),  # Output for processed image file\n",
    "        \"state\"  # Hidden state output\n",
    "    ],\n",
    "    title=\"Depth of Field Simulation\",\n",
    "    description=\"Upload an original image to generate a depth map and apply a shallow depth of field effect.\",\n",
    "    allow_flagging=\"never\"  # Disable flagging feature\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(debug=True)  # Launch the Gradio interface in debug mode\n",
    "\n",
    "# Clean up temporary files\n",
    "def cleanup(files):\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)  # Remove temporary files\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning up file {file}: {str(e)}\")\n",
    "\n",
    "# Register cleanup function\n",
    "import atexit\n",
    "atexit.register(cleanup, [])  # Register cleanup function to run at exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ef702-299e-4abc-a6a6-eda3caa1761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56daa06a-05f4-4f2b-a4c8-2b8adb4e58c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a3e7306a-841c-422d-a80d-e0480abce700",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777c8bb-e055-4ebe-9d5d-c2ca8eeba31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23230f0d-d9b0-4200-8a72-c72f63b31797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a81dcc-6c12-41d8-9152-d20390a274f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba695a0-bb0b-400f-861c-c954ba32b923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d44d0-f8fe-451b-a750-fb478851bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
